{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy_of_assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J26xzhfHmwag",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Named entity recognition\n",
        "\n",
        "Create a model for Named Entity Recognition for dataset CoNLL 2002.  \n",
        "Your quality metric = f1_macro\n",
        "\n",
        "In your solution you should use: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost)   \n",
        "Tutorials:  \n",
        "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
        "1. https://github.com/catboost/tutorials \n",
        "\n",
        "More baselines you beat - better your score\n",
        " \n",
        "baseline 1 [3 points]: 0.0604      random labels  \n",
        "baseline 2 [5 points]: 0.3966      PoS features + logistic regression  \n",
        "baseline 3 [8 points]: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
        "\n",
        "[1 point] using feature engineering (creating features not presented in the baselines)\n",
        "\n",
        "! Your results must be reproducible. You should explicitly set all seeds random_states in yout model.  \n",
        "! Remember to use proper training pipeline.  \n",
        "\n",
        "bonus, think about:  \n",
        "1. [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHlPEYnlmynP",
        "colab_type": "code",
        "outputId": "83bcfd9b-d3f5-4285-e244-55e5d62bb8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "!wget 'https://www.dropbox.com/s/0nzylhci63vsfcv/data.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-03 20:35:20--  https://www.dropbox.com/s/0nzylhci63vsfcv/data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/0nzylhci63vsfcv/data.zip [following]\n",
            "--2019-12-03 20:35:20--  https://www.dropbox.com/s/raw/0nzylhci63vsfcv/data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com/cd/0/inline/AtjlGMEyldqgnMroVTS6giWss-ikwImz9MIpvXoVHrG9Ro24TGH5RwBzOVbiEXxBvktCPLPHf9C9mkN17on2SgdBU35zpGZGMDcx1TCmpixZZ2TmIj-gGFhLUCO1j507tCE/file# [following]\n",
            "--2019-12-03 20:35:20--  https://ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com/cd/0/inline/AtjlGMEyldqgnMroVTS6giWss-ikwImz9MIpvXoVHrG9Ro24TGH5RwBzOVbiEXxBvktCPLPHf9C9mkN17on2SgdBU35zpGZGMDcx1TCmpixZZ2TmIj-gGFhLUCO1j507tCE/file\n",
            "Resolving ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com (ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com (ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/Ati9SGYIy3EdU1CvJy4ria83D67GdZr07BkOvoXnUnG6SChXhYVK7ahQqCkK0U8mGktrCtBdkMIT_IULxEwjENPVu9J74HSjA3QvmKt97YsGIGRoilmZEVxpIbmS852QZdh8JpEoVNTQip826uw8FJF5ojxa6Y1iQXQrET5kT5ByI-QXoT5cTYvm42GvvcYp65F2H5WqEw4TPFxObd5KiUr9FZcmxZH4Gi89eYmPDzKajig8jzI8IWbvVia8OFMpyaCDm3ATlcxYExm_wfcrKPMIu98J183YZHorfi_cBqHEZZnIVT0LXpVwqBr5otsI3Dhq7zLwCbCcmXUXh4Wo666_r0S4MWl0yeJiftaVoPGWlQ/file [following]\n",
            "--2019-12-03 20:35:21--  https://ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com/cd/0/inline2/Ati9SGYIy3EdU1CvJy4ria83D67GdZr07BkOvoXnUnG6SChXhYVK7ahQqCkK0U8mGktrCtBdkMIT_IULxEwjENPVu9J74HSjA3QvmKt97YsGIGRoilmZEVxpIbmS852QZdh8JpEoVNTQip826uw8FJF5ojxa6Y1iQXQrET5kT5ByI-QXoT5cTYvm42GvvcYp65F2H5WqEw4TPFxObd5KiUr9FZcmxZH4Gi89eYmPDzKajig8jzI8IWbvVia8OFMpyaCDm3ATlcxYExm_wfcrKPMIu98J183YZHorfi_cBqHEZZnIVT0LXpVwqBr5otsI3Dhq7zLwCbCcmXUXh4Wo666_r0S4MWl0yeJiftaVoPGWlQ/file\n",
            "Reusing existing connection to ucfc2b1df4a567c4e4e60cc3fb3c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1064698 (1.0M) [application/zip]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "data.zip.1          100%[===================>]   1.01M  4.43MB/s    in 0.2s    \n",
            "\n",
            "2019-12-03 20:35:22 (4.43 MB/s) - ‘data.zip.1’ saved [1064698/1064698]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXj3XXd6wqv2",
        "colab_type": "code",
        "outputId": "3af51194-77b2-4b23-8e04-231c3037d92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!unzip 'data.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/.DS_Store          \n",
            "replace __MACOSX/data/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "replace data/ner_short.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/ner_short.csv      \n",
            "replace __MACOSX/data/._ner_short.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/data/._ner_short.csv  \n",
            "replace __MACOSX/._data? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._data         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tM6Z2rqmwak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "SEED=1337"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFErMs5lmwao",
        "colab_type": "code",
        "outputId": "dda41d56-31b0-458a-f86b-a20f2bffa927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "df = pd.read_csv('data/ner_short.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  next-next-pos next-next-word next-pos  ... sentence_idx           word tag\n",
              "0           NNS  demonstrators       IN  ...          1.0      Thousands   O\n",
              "1           VBP           have      NNS  ...          1.0             of   O\n",
              "2           VBN        marched      VBP  ...          1.0  demonstrators   O\n",
              "3            IN        through      VBN  ...          1.0           have   O\n",
              "4           NNP         London       IN  ...          1.0        marched   O\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNUAsUlAmwav",
        "colab_type": "code",
        "outputId": "9d57aa23-8905-4eab-8883-6440c24df2f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# number of sentences\n",
        "df.sentence_idx.max()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5fgafqmwaz",
        "colab_type": "code",
        "outputId": "71025f31-331e-415c-ecaf-88cfe8f5e057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "# class distribution\n",
        "df.tag.value_counts(normalize=True )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        0.852828\n",
              "B-geo    0.027604\n",
              "B-gpe    0.020935\n",
              "B-org    0.020247\n",
              "I-per    0.017795\n",
              "B-tim    0.016927\n",
              "B-per    0.015312\n",
              "I-org    0.013937\n",
              "I-geo    0.005383\n",
              "I-tim    0.004247\n",
              "B-art    0.001376\n",
              "I-gpe    0.000837\n",
              "I-art    0.000748\n",
              "B-eve    0.000628\n",
              "I-eve    0.000508\n",
              "B-nat    0.000449\n",
              "I-nat    0.000239\n",
              "Name: tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVBO8kf5mwa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence length\n",
        "tdf = df.set_index('sentence_idx')\n",
        "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
        "df = tdf.reset_index(drop=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNlborKhmwa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode categorial variables\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['pos'] = le.fit_transform(df.pos)\n",
        "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFIevmj2mwbB",
        "colab_type": "code",
        "outputId": "586e6c2b-b4ba-47fb-b694-42d6d66ae4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_idx  next-next-pos next-next-word  ...           word tag  length\n",
              "0           1.0             18  demonstrators  ...      Thousands   O      48\n",
              "1           1.0             33           have  ...             of   O      48\n",
              "2           1.0             32        marched  ...  demonstrators   O      48\n",
              "3           1.0              9        through  ...           have   O      48\n",
              "4           1.0             16         London  ...        marched   O      48\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwqjdBvAmwbD",
        "colab_type": "code",
        "outputId": "f4e935e7-774f-4dea-c5b4-a555a529e4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# splitting\n",
        "y = LabelEncoder().fit_transform(df.tag)\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
        "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uFChIBkmwbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some wrappers to work with word2vec\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from collections import defaultdict\n",
        "\n",
        "   \n",
        "class Word2VecWrapper(TransformerMixin):\n",
        "    def __init__(self, window=5,negative=5, size=300, iter=100, is_cbow=False, random_state=SEED):\n",
        "        self.window_ = window\n",
        "        self.negative_ = negative\n",
        "        self.size_ = size\n",
        "        self.iter_ = iter\n",
        "        self.is_cbow_ = is_cbow\n",
        "        self.w2v = None\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def get_size(self):\n",
        "        return self.size_\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        X: list of strings\n",
        "        \"\"\"\n",
        "        sentences_list = [x.split() for x in X]\n",
        "        self.w2v = Word2Vec(sentences_list, \n",
        "                            window=self.window_,\n",
        "                            negative=self.negative_, \n",
        "                            size=self.size_, \n",
        "                            iter=self.iter_,\n",
        "                            sg=not self.is_cbow_, seed=self.random_state)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def has(self, word):\n",
        "        return word in self.w2v\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        X: a list of words\n",
        "        \"\"\"\n",
        "        if self.w2v is None:\n",
        "            raise Exception('model not fitted')\n",
        "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcXvLTHQmwbJ",
        "colab_type": "code",
        "outputId": "50589f35-67d5-4048-a1e0-82eea1f8ab33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "# here we exploit that word2vec is an unsupervised learning algorithm\n",
        "# so we can train it on the whole dataset (subject to discussion)\n",
        "\n",
        "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
        "\n",
        "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow.fit(sentences_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 44.9 s, sys: 472 ms, total: 45.4 s\n",
            "Wall time: 19.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjPs42FmwbP",
        "colab_type": "code",
        "outputId": "2eb6b437-b547-4a8f-8df1-2489b5ed229a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%time\n",
        "# baseline 1 \n",
        "# random labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', DummyClassifier(random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.05887736725599869\n",
            "test 0.060439542712750365\n",
            "CPU times: user 132 ms, sys: 12 ms, total: 144 ms\n",
            "Wall time: 142 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uef-pDLimwbS",
        "colab_type": "code",
        "outputId": "d89e1089-55a5-4e7f-ee69-8cf1d91ea985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "%%time\n",
        "# baseline 2 \n",
        "# pos features + one hot encoding + logistic regression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
        "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-638a648af069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# baseline 2 \\n# pos features + one hot encoding + logistic regression\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\n\\ncolumns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\\n\\nmodel = Pipeline([\\n    ('enc', OneHotEncoder()),\\n    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \\n                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\\n])\\n\\nmodel.fit(df_train[columns], y_train)\\n\\nprint('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\\nprint('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2083\u001b[0m                       \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                       )\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             for l1_ratio in l1_ratios_)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6jCiWSjmwbV",
        "colab_type": "code",
        "outputId": "4f2b03ec-07f7-437b-d4be-0bc003fc347d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "%%time\n",
        "# baseline 3\n",
        "# use word2vec cbow embedding + baseline 2 + svm\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import scipy.sparse as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word']),\n",
        "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word']),\n",
        "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "\n",
        "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
        "                                    {'C': np.logspace(-4, 0, 5)}, \n",
        "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-49d90620f6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# baseline 3\\n# use word2vec cbow embedding + baseline 2 + svm\\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\\nfrom sklearn.svm import LinearSVC\\nimport scipy.sparse as sp\\n\\nembeding = w2v_cbow\\nencoder_pos = OneHotEncoder()\\nX_train = sp.hstack([\\n    embeding.transform(df_train.word),\\n    embeding.transform(df_train['next-word']),\\n    embeding.transform(df_train['next-next-word']),\\n    embeding.transform(df_train['prev-word']),\\n    embeding.transform(df_train['prev-prev-word']),\\n    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\\n])\\nX_test = sp.hstack([\\n    embeding.transform(df_test.word),\\n    embeding.transform(df_test['next-word']),\\n    embeding.transform(df_test['next-next-word']),\\n    embeding.transform(df_test['prev-word']),\\n    embeding.transform(df_test['prev-prev-word']),\\n    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\\n])\\n\\nmodel = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \\n                                    {'C': np.logspace(-4, 0, 5)}, \\n                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)\\n\\nprint('train', metrics.f1_score(y_train, mod...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-23b8a3250060>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-23b8a3250060>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YP8KkUN2IvN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## baseline 1 [3 points]: 0.0604 random labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7v7Cye0-FvK",
        "colab_type": "code",
        "outputId": "3a6b907d-d0da-460c-ee84-a127bb3c9dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('xgb', XGBClassifier(n_estimators=100, random_state=SEED))\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.39326124218078107\n",
            "test 0.3353187957066505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_l7m7zh-TPZ",
        "colab_type": "text"
      },
      "source": [
        "## baseline 2 [5 points]: 0.3966 PoS features + logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWOWIKa4UjDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d60a4718-f545-4dd9-aa41-cd1b29e6aa24"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.7454472092450833\n",
            "test 0.5677295536016972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLL-XIyO_MBc",
        "colab_type": "text"
      },
      "source": [
        "## baseline 3 [8 points]: 0.8122 word2vec cbow embedding + baseline 2 + svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vZ912Lg3Mow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9538f969-fa47-4ef5-8772-80f74db0159e"
      },
      "source": [
        "import scipy as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word'])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word'])\n",
        "])\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, np.around(model.predict(X_train), 0), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, np.around(model.predict(X_test), 0), average='macro'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.9620222651276005\n",
            "test 0.8035519282076781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBvirYkv2wGO",
        "colab_type": "text"
      },
      "source": [
        "# [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?\n",
        "F1 сочетает в себе 2 параметра - точность и recall, а также он может показать группировку прогнозируемых данных. Мы могли бы использовать любую другую усредняющую метрику, но только с помощью f1 мы можем получить двоичную классификацию."
      ]
    }
  ]
}