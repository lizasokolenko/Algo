{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exam.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0097T1LH8NzR",
        "colab_type": "text"
      },
      "source": [
        "## Question 10\n",
        "Seq2seq models are trained by maximizing the likelihood of next token given: the output from the previous node of the decoder, depending on output of the previous state and the input summary while in inference each word is generated sequentially only based on previously generated words (previous LSTM decoder step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkbL-gfBy1Fx",
        "colab_type": "text"
      },
      "source": [
        "## Var 2\n",
        "Develop a model for predicting review rating.\n",
        "Binary classification:\n",
        "positive class: target = 5\n",
        "negative class: target = 1,2,3,4\n",
        "Score: binary F1\n",
        "You are forbidden to use test dataset for any kind of training.\n",
        "Remember proper training pipeline.\n",
        "If you are not using default params in the models, you have to use some validation scheme to justify them.\n",
        "\n",
        "Use random_state or seed params - your experiment must be reprodusible.\n",
        "\n",
        "## 1 baseline = 0.720\n",
        "## 2 baseline = 0.745"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckm6NgJBsxmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import spacy\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "SEED=1337\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD-yQtKDzKHn",
        "colab_type": "code",
        "outputId": "2c1b38ef-76ce-4634-f4ce-bbe051deee1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_train['target'] = (df_train['target'] == 5).astype(np.int)\n",
        "df_test['target'] = (df_test['target'] == 5).astype(np.int)\n",
        "\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48192, 3), (5355, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NPzVDRpGRbk",
        "colab_type": "code",
        "outputId": "1682b1c6-bfcc-4016-f60f-cb334c179ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>title</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The staff was very friendly, the breakfast ver...</td>\n",
              "      <td>Walker Gem</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Excellent service - very approachable and prof...</td>\n",
              "      <td>Excellent Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really a top notch place to spend a day at the...</td>\n",
              "      <td>Good location, warm and friendly staff</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a little noisy, there was a false fire alarm a...</td>\n",
              "      <td>nice hotel,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Place had too many animals and I'm allergic to...</td>\n",
              "      <td>Experience</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48187</th>\n",
              "      <td>A friend of mine always books the cheapest, ba...</td>\n",
              "      <td>Comfy, cozy but oh, so grand!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48188</th>\n",
              "      <td>Stayed here with my family over Spring Break i...</td>\n",
              "      <td>Great location and price for family lodging.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48189</th>\n",
              "      <td>One word AWFUL and the pool was closed</td>\n",
              "      <td>Good hotel in a quiet part of Memphis</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48190</th>\n",
              "      <td>Never will stay here again. Dirty towels shirt...</td>\n",
              "      <td>Filthy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48191</th>\n",
              "      <td>This Inn had been renovated and the staff were...</td>\n",
              "      <td>Christmas Fun!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48192 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  ... target\n",
              "0      The staff was very friendly, the breakfast ver...  ...      1\n",
              "1      Excellent service - very approachable and prof...  ...      0\n",
              "2      Really a top notch place to spend a day at the...  ...      1\n",
              "3      a little noisy, there was a false fire alarm a...  ...      0\n",
              "4      Place had too many animals and I'm allergic to...  ...      0\n",
              "...                                                  ...  ...    ...\n",
              "48187  A friend of mine always books the cheapest, ba...  ...      0\n",
              "48188  Stayed here with my family over Spring Break i...  ...      0\n",
              "48189             One word AWFUL and the pool was closed  ...      0\n",
              "48190  Never will stay here again. Dirty towels shirt...  ...      0\n",
              "48191  This Inn had been renovated and the staff were...  ...      0\n",
              "\n",
              "[48192 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKpBXLeCGeOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train['review']\n",
        "y_train = df_train['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVCE23UMI-rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(max_df=0.5, min_df=10)\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "\n",
        "test_data = df_test\n",
        "X_test = tfidf.transform(test_data['review'])\n",
        "y_test = test_data['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtKmVCAuCj4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0bb1287e-5196-40b5-a860-3b95c0c4ebf4"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0/(1.0 + np.e**(-z))\n",
        "\n",
        "class LogRegNumpy(ClassifierMixin):\n",
        "    def __init__(self, llambda=1, lr=0.1, batch_size=32, n_epochs=100):\n",
        "        \n",
        "        self.w = None\n",
        "        self.b = 0\n",
        "        self.llambda = llambda\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "        self.history = []\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.w = np.random.randn(X.shape[1])\n",
        "        self.b = 0\n",
        "        \n",
        "        for epoch in range(self.n_epochs):\n",
        "            \n",
        "            # random permutation over indices of dataset\n",
        "            batch_indices = np.random.permutation(len(y))\n",
        "            \n",
        "            for j in range(0, len(y), self.batch_size):\n",
        "                batch_idx = batch_indices[j:j+32]\n",
        "                batch_X = X[batch_idx]\n",
        "                batch_y = y[batch_idx]\n",
        "                \n",
        "                # forward pass\n",
        "                # <TODO> [1 point] calculate batch loss\n",
        "                \n",
        "                z = batch_X @ self.w + self.b\n",
        "                batch_y_hat = sigmoid(z)\n",
        "                \n",
        "                loss = -np.mean(batch_y * np.log(batch_y_hat) + (1 - batch_y) * np.log(1 - batch_y_hat)) + 0.5*self.llambda * self.w.T @ self.w\n",
        "#                 print(loss)\n",
        "                # backward pass\n",
        "                # <TODO> [2 points] calculate batch gradients \n",
        "                grad_z = sigmoid(z) - batch_y\n",
        "                grad_w = batch_X.T @ (batch_y_hat - batch_y) * (1.0/self.batch_size) + self.llambda * self.w\n",
        "                grad_b = np.mean(grad_z)\n",
        "\n",
        "                # SGD optimization step\n",
        "                # <TODO> [1 point]\n",
        "                self.w = self.w - self.lr * grad_w\n",
        "                self.b = self.b - self.lr * grad_b\n",
        "                \n",
        "                self.history.append(loss)\n",
        "        \n",
        "        return self \n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        # <TODO> [1 point] calculate p(y=1 | x)\n",
        "        p = sigmoid(X @ self.w + self.b)\n",
        "        return p\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X) > 0.5).astype(np.int)\n",
        "    \n",
        "    \n",
        "model = LogRegNumpy(llambda = 0.001, lr=3, batch_size=128, n_epochs=100)\n",
        "model.fit(X_train, y_train)\n",
        "print('auc', metrics.roc_auc_score(y_test, model.predict_proba(X_test)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc 0.814824124309457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdDOv2GxNZcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def train_valid_pipeline(model, X_train, y_train, X_test, y_test, params):\n",
        "  model.fit(X_train, y_train)\n",
        "  print(\"f1_score on train: \", f1_score(y_train, model.predict(X_train)))\n",
        "\n",
        "  valid = GridSearchCV(model, param_grid = params, cv = 5)\n",
        "  valid.fit(X_train, y_train)\n",
        "  print(\"f1_score after regularization: \", f1_score(y_train, valid.predict(X_train)))\n",
        "  print(\"Best params: \", valid.best_params_)\n",
        "  model = valid.best_estimator_\n",
        "\n",
        "  print(\"f1_score on test: \", f1_score(y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RadJBJIPR-H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b3abf645-f94e-4250-d59c-40097d700326"
      },
      "source": [
        "hyper_param = {'dual' : [True, False], 'C': np.arange(.01,1,.01), 'solver' : ['liblinear'], 'random_state': [50, 43, 25] }\n",
        "train_valid_pipeline(model, X_train, y_train, X_test, y_test, hyper_param)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score on train:  0.14621434222160176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e984081f98d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhyper_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dual'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'solver'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'random_state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_valid_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-395f511620a9>\u001b[0m in \u001b[0;36mtrain_valid_pipeline\u001b[0;34m(model, X_train, y_train, X_test, y_test, params)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score after regularization: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m                             \u001b[0;34m\"it does not seem to be a scikit-learn estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                             \u001b[0;34m\"as it does not implement a 'get_params' methods.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                             % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<__main__.LogRegNumpy object at 0x7fcf46305470>' (type <class '__main__.LogRegNumpy'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGsemANdzaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}